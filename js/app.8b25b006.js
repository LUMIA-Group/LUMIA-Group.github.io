(function(){"use strict";var e={7051:function(e,t,a){var s=a(7195),i=function(){var e=this,t=e._self._c;return t("div",{attrs:{id:"app"}},[t("app-header"),t("router-view")],1)},n=[],r=function(){var e=this,t=e._self._c;return t("div",{staticClass:"header-container"},[t("el-row",{staticClass:"header-content"},[t("el-col",{attrs:{span:8}},[t("div",{staticClass:"header-logo",on:{click:function(t){return e.clickHeader({value:"home"})}}},[t("img",{staticClass:"logo",attrs:{src:e.headerData.logo||"https://vi.sjtu.edu.cn/img/brand-logo-s-w.png",alt:"",srcset:""}}),t("span",{staticClass:"name"},[e._v(e._s(e.headerData.name))])])]),t("el-col",{attrs:{span:16}},[t("ul",{staticClass:"header-list"},e._l(e.headerData.headerList,(function(a){return t("li",{key:a.value,staticClass:"header-item",class:{active:e.activeHeader===a.value},on:{click:function(t){return e.clickHeader(a)}}},[e._v(" "+e._s(a.label)+" ")])})),0)])],1)],1)},o=[];a(7658);const c={name:"Name",logo:"",headerList:[{value:"people",label:"People"},{value:"research",label:"Research"},{value:"news",label:"News"},{value:"http://github",label:"Github",type:"link"},{value:"contact",label:"Contact"}]};var l={data(){return{headerData:c,activeHeader:""}},mounted(){this.activeHeader=this.$route.name},methods:{clickHeader(e){this.activeHeader=e.value,"link"===e.type?window.open(e.value,"_blank"):this.$route.name!==e.value&&this.$router.push({name:e.value})}}},p=l,h=a(1001),d=(0,h.Z)(p,r,o,!1,null,"3dfd6b96",null),u=d.exports,m={components:{appHeader:u}},g=m,f=(0,h.Z)(g,i,n,!1,null,null,null),v=f.exports,w=a(2241),y=function(){var e=this,t=e._self._c;return t("div",{staticClass:"home-container"},[t("div",{staticClass:"home-content"},[t("section",{staticClass:"introduction"},[t("h1",[e._v(e._s(e.homeData.name))]),t("h2",[e._v(" "+e._s(e.homeData.desc)+" ")])]),t("section",{staticClass:"project-list"},[t("el-row",{attrs:{gutter:32}},e._l(e.homeData.projectList,(function(e){return t("el-col",{key:e.id,staticClass:"peoject-container"},[t("section",{staticClass:"project-item"},[t("div",[t("img",{attrs:{src:e.img,alt:"",srcset:"",width:"100%"}})])])])})),1)],1)])])},_=[];const b={name:"New Name",desc:"Our latest web design tips, tricks, insights, and resources, hot offthe presses.",projectList:[{id:1,img:"./static/testimg.png",name:"Name1",intro:"This is ……"}]};var C={name:"homepage",data(){return{homeData:b}}},k=C,T=(0,h.Z)(k,y,_,!1,null,"3f67d61b",null),S=T.exports,x=function(){var e=this,t=e._self._c;return t("div",{staticClass:"people-container"},[t("div",{staticClass:"people-content"},[t("el-collapse",{model:{value:e.activeNames,callback:function(t){e.activeNames=t},expression:"activeNames"}},[t("el-collapse-item",{attrs:{title:"Name 1",name:"1"}},[t("ul",{staticClass:"s-list"},e._l(e.peopleData.studentsList,(function(a,s){return t("li",{key:s,staticClass:"s-item"},[t("img",{attrs:{src:a.pic,alt:"",srcset:"",width:"100%"}}),t("h3",{staticClass:"s-name"},[e._v(e._s(a.name))]),t("p",[e._v(e._s(a.grade))])])})),0)]),t("el-collapse-item",{attrs:{title:"Name 2",name:"2"}},[t("ul",{staticClass:"s-list"},e._l(e.peopleData.teachersList,(function(a,s){return t("li",{key:s,staticClass:"s-item"},[t("img",{attrs:{src:a.pic,alt:"",srcset:"",width:"100%"}}),t("h3",{staticClass:"s-name"},[e._v(e._s(a.name))]),t("p",[e._v(e._s(a.grade))])])})),0)]),t("el-collapse-item",{attrs:{title:"Name 3",name:"3"}},[t("ul",{staticClass:"s-list"},e._l(e.studentsList,(function(a,s){return t("li",{key:s,staticClass:"s-item"},[t("img",{attrs:{src:a.pic,alt:"",srcset:"",width:"100%"}}),t("h3",{staticClass:"s-name"},[e._v(e._s(a.name))]),t("p",[e._v(e._s(a.grade))])])})),0)])],1)],1)])},L=[];const A={studentsList:[{name:"A student",pic:"./static/testpeople.png",grade:"XXXX",homepage:""},{name:"A student",pic:"./static/testimg.png",grade:"XXXX",homepage:""},{name:"A student",pic:"./static/testpeople.png",grade:"XXXX",homepage:""},{name:"A student",pic:"./static/testimg.png",grade:"XXXX",homepage:""},{name:"A student",pic:"./static/testimg2.png",grade:"XXXX",homepage:""},{name:"A student",pic:"./static/testpeople.png",grade:"XXXX",homepage:""},{name:"A student",pic:"./static/testimg.png",grade:"XXXX",homepage:""},{name:"A student",pic:"./static/testpeople.png",grade:"XXXX",homepage:""}],teachersList:[{name:"A student",pic:"./static/testpeople.png",grade:"XXXX",homepage:""},{name:"A student",pic:"./static/testimg.png",grade:"XXXX",homepage:""},{name:"A student",pic:"./static/testpeople.png",grade:"XXXX",homepage:""},{name:"A student",pic:"./static/testimg.png",grade:"XXXX",homepage:""},{name:"A student",pic:"./static/testimg2.png",grade:"XXXX",homepage:""},{name:"A student",pic:"./static/testpeople.png",grade:"XXXX",homepage:""},{name:"A student",pic:"./static/testimg.png",grade:"XXXX",homepage:""},{name:"A student",pic:"./static/testpeople.png",grade:"XXXX",homepage:""}]};var X={data(){return{peopleData:A,activeNames:"1"}}},Z=X,P=(0,h.Z)(Z,x,L,!1,null,"0d8ec9a6",null),I=P.exports,N=function(){var e=this;e._self._c;return e._m(0)},D=[function(){var e=this,t=e._self._c;return t("div",{staticClass:"research-container"},[t("div",{staticClass:"research-content"},[t("section",{staticClass:"section-item",attrs:{id:"publications"}},[t("section",{staticClass:"research-section"},[t("div",{staticClass:"row"},[t("div",{staticClass:"col-xs-12 col-sm-4"},[t("img",{attrs:{width:"100%",src:a(9597),alt:"",srcset:""}})]),t("div",{staticClass:"col-xs-12 col-sm-8"},[t("h4",[e._v(" Fourier Transformer: Fast Long Range Modeling by Removing Sequence Redundancy with FFT Operator ")]),t("p",{staticClass:"author"},[e._v(" Ziwei He, Meng Yang, Minwei Feng, Jingcheng Yin, Xinbing Wang, Jingwen Leng, "),t("span",{staticStyle:{"font-weight":"500"}},[e._v("Zhouhan Lin#")])]),t("div",{staticClass:"link-list"},[t("span",[e._v("ACL 2023 (Findings) ")]),t("span",[e._v(" | ")]),t("a",{attrs:{href:"https://aclanthology.org/2023.findings-acl.570.pdf"}},[t("span",[e._v("pdf")])]),t("span",[e._v(" | ")]),t("a",{attrs:{href:"https://github.com/LUMIA-Group/FourierTransformer"}},[t("span",[e._v("codes")])])]),t("article",[e._v(" We propose Fourier Transformer, a simple yet effective approach by layer-wise progressively removing sequence redundancies in hidden states using the ready-made Fast Fourier Transform (FFT) operator to perform Discrete Cosine Transformation (DCT). Fourier Transformer is able to significantly reduce computational costs while retaining the ability to inherit from various large pretrained models. SOTA performances among all transformer-based models on the LRA benchmark with significant improvement in both speed and space. For generative seq-to-seq tasks including CNN/DailyMail and ELI5, by inheriting the BART weights our model outperforms the standard BART and other efficient models. ")])])]),t("div",{staticClass:"row"},[t("div",{staticClass:"col-xs-12 col-sm-4"},[t("img",{attrs:{width:"100%",src:a(9149),alt:"",srcset:""}})]),t("div",{staticClass:"col-xs-12 col-sm-8"},[t("h4",[e._v(" Text Classification In The Wild: A Large-Scale Long-Tailed Name Normalization Dataset ")]),t("p",{staticClass:"author"},[e._v(" Jiexing Qi, Shuhao Li, Zhixin Guo, Yusheng Huang, Chenghu Zhou, Weinan Zhang, Xinbing Wang, "),t("span",{staticStyle:{"font-weight":"500"}},[e._v("Zhouhan Lin#")])]),t("div",{staticClass:"link-list"},[t("span",[e._v("ICASSP 2023 ")]),t("span",[e._v(" | ")]),t("a",{attrs:{href:"https://arxiv.org/pdf/2302.09509.pdf"}},[t("span",[e._v("pdf")])]),t("span",[e._v(" | ")]),t("a",{attrs:{href:"https://github.com/LUMIA-Group/LoT-insts"}},[t("span",[e._v("codes")])])]),t("article",[e._v(" In this work, we first collect a large-scale institution name normalization dataset LoT-insts, which contains over 25k classes that exhibit a naturally long-tailed distribution. In order to isolate the few-shot and zero-shot learning scenarios from the massive many-shot classes, we construct our test set from four different subsets: many-, medium-, and few-shot sets, as well as a zero-shot open set. We believe it provides an important and different scenario to study this problem. ")])])]),t("div",{staticClass:"row"},[t("div",{staticClass:"col-xs-12 col-sm-4"},[t("img",{attrs:{width:"100%",src:a(389),alt:"",srcset:""}})]),t("div",{staticClass:"col-xs-12 col-sm-8"},[t("h4",[e._v(" Ordered GNN: Ordering Message Passing to Deal with Heterophily and Over-smoothing ")]),t("p",{staticClass:"author"},[e._v(" Yunchong Song, Chenghu Zhou, Xinbing Wang, "),t("span",{staticStyle:{"font-weight":"500"}},[e._v("Zhouhan Lin#")])]),t("div",{staticClass:"link-list"},[t("span",[e._v("ICLR 2023 ")]),t("span",[e._v(" | ")]),t("a",{attrs:{href:"https://arxiv.org/pdf/2302.01524.pdf"}},[t("span",[e._v("pdf")])]),t("span",[e._v(" | ")]),t("a",{attrs:{href:"https://github.com/LUMIA-Group/OrderedGNN"}},[t("span",[e._v("codes")])])]),t("article",[e._v(" In this work, we propose to tackle both heterophily and over-smoothing problems by an ordered message passing mecanism, with specific blocks of neurons in a node embedding targeted for messages passed from neighboring nodes that are located within specific hops. This is achieved by aligning the hierarchy of the rooted-tree of a central node with the ordered neurons in its node representation. SOTA performance in both homophily and heterophily settings without any targeted design, robust to a wide number of layers, and explainable. ")])])]),t("div",{staticClass:"row"},[t("div",{staticClass:"col-xs-12 col-sm-4"},[t("img",{attrs:{width:"100%",src:a(5660),alt:"",srcset:""}})]),t("div",{staticClass:"col-xs-12 col-sm-8"},[t("h4",[e._v(" RASAT: Integrating Relational Structures into Pretrained Seq2Seq Model for Text-to-SQL ")]),t("p",{staticClass:"author"},[e._v(" Jiexing Qi, Jingyao Tang, Ziwei He, Xiangpeng Wan, Yu Cheng, Chenghu Zhou, Xinbing Wang, Quanshi Zhang, "),t("span",{staticStyle:{"font-weight":"500"}},[e._v("Zhouhan Lin#")])]),t("div",{staticClass:"link-list"},[t("span",[e._v("EMNLP 2022 ")]),t("span",[e._v(" | ")]),t("a",{attrs:{href:"https://arxiv.org/pdf/2205.06983.pdf"}},[t("span",[e._v("pdf")])]),t("span",[e._v(" | ")]),t("a",{attrs:{href:"https://github.com/LUMIA-Group/rasat"}},[t("span",[e._v("codes")])])]),t("article",[e._v(" Relational structures such as schema linking and schema encoding have been validated as a key component to qualitatively translating natural language into SQL queries. We propose RASAT: a Transformer seq2seq architecture augmented with relation-aware self-attention that could leverage a variety of relational structures while still being able to inherit the pretrained parameters from the T5 model effectively. Our model can incorporate almost all types of existing relations in the literature. Experimental results on three widely used text-to-SQL datasets, covering both single-turn and multi-turn scenarios, have shown that RASAT could achieve state-of-the-art results across all three benchmarks (75.5% EX on Spider, 52.6% IEX on SParC, and 37.4% IEX on CoSQL). ")])])]),t("div",{staticClass:"row"},[t("div",{staticClass:"col-xs-12 col-sm-4"},[t("img",{attrs:{width:"100%",src:a(63),alt:"",srcset:""}})]),t("div",{staticClass:"col-xs-12 col-sm-8"},[t("h4",[e._v(" Syntax-guided Localized Self-attention by Constituency Syntactic Distance ")]),t("p",{staticClass:"author"},[e._v(" Shengyuan Hou*, Jushi Kai*, Haotian Xue*, Bingyu Zhu, Bo Yuan, Longtao Huang, Xinbing Wang, "),t("span",{staticStyle:{"font-weight":"500"}},[e._v("Zhouhan Lin#")])]),t("div",{staticClass:"link-list"},[t("span",[e._v("EMNLP 2022 (Findings) ")]),t("span",[e._v(" | ")]),t("a",{attrs:{href:"https://arxiv.org/pdf/2210.11759.pdf"}},[t("span",[e._v("pdf")])]),t("span",[e._v(" | ")]),t("a",{attrs:{href:"https://github.com/LUMIA-Group/distance_transformer"}},[t("span",[e._v("codes")])])]),t("article",[e._v(" We propose a syntax-guided localized self-attention for Transformer that allows directly incorporating grammar structures from an external constituency parser. It prohibits the attention mechanism from overweight the grammatically distant tokens over close ones. ")])])]),t("div",{staticClass:"row"},[t("div",{staticClass:"col-xs-12 col-sm-4"},[t("img",{attrs:{width:"100%",src:a(3145),alt:"",srcset:""}})]),t("div",{staticClass:"col-xs-12 col-sm-8"},[t("h4",[e._v(" Leveraging Unimodal Self-Supervised Learning for Multimodal Audio-Visual Speech Recognition ")]),t("p",{staticClass:"author"},[e._v(" Xichen Pan, Peiyu Chen, Yichen Gong, Helong Zhou, Xinbing Wang, "),t("span",{staticStyle:{"font-weight":"500"}},[e._v("Zhouhan Lin#")])]),t("div",{staticClass:"link-list"},[t("span",[e._v(" ACL 2022 ")]),t("span",[e._v(" | ")]),t("a",{attrs:{href:"https://arxiv.org/pdf/2203.07996.pdf"}},[t("span",[e._v("pdf")])]),t("span",[e._v(" | ")]),t("a",{attrs:{href:"https://github.com/LUMIA-Group/Leveraging-Self-Supervised-Learning-for-AVSR"}},[t("span",[e._v("codes")])])]),t("article",[e._v(" In this work, we successfully leverage unimodal self-supervised learning to promote the multimodal AVSR. In particular, audio and visual front-ends are trained on large-scale unimodal datasets, and then we integrate components of both front-ends into a larger multimodal framework that learns to recognize parallel audio-visual data into characters through a combination of CTC and seq2seq decoding. We show that both components inherited from unimodal self-supervised learning cooperate well, resulting in the multimodal framework yielding competitive results through fine-tuning. Even without an external language model, our proposed model raises the SOTA performances on the widely accepted Lip Reading Sentences 2 (LRS2) dataset by a large margin, with a relative improvement of 30%. ")])])]),t("div",{staticClass:"row"},[t("div",{staticClass:"col-xs-12 col-sm-4"},[t("img",{attrs:{width:"100%",src:a(1121),alt:"",srcset:""}})]),t("div",{staticClass:"col-xs-12 col-sm-8"},[t("h4",[e._v("Block-Skim: Efficient Question Answering for Transformer")]),t("p",{staticClass:"author"},[e._v(" Yue Guan, Zhengyi Li, Jingwen Leng#, "),t("span",{staticStyle:{"font-weight":"500"}},[e._v("Zhouhan Lin#")]),e._v(", Minyi Guo, Yuhao Zhu ")]),t("div",{staticClass:"link-list"},[t("span",[e._v(" AAAI 2022 ")]),t("span",[e._v(" | ")]),t("a",{attrs:{href:"https://arxiv.org/pdf/2112.08560.pdf"}},[t("span",[e._v("pdf")])]),t("span",[e._v(" | ")]),t("a",{attrs:{href:"https://github.com/chandlerguan/blockskim"}},[t("span",[e._v("codes")])])]),t("article",[e._v(" We propose Block-skim, which learns to skim unnecessary context in higher hidden layers to improve and accelerate the Transformer performance. The key idea of Block-Skim is to identify the context that must be further processed and those that could be safely discarded early on during inference. Critically, we find that such information could be sufficiently derived from the self-attention weights inside the Transformer model. We further prune the hidden states corresponding to the unnecessary positions early in lower layers, achieving significant inference-time speedup. To our surprise, we observe that models pruned in this way outperform their full-size counterparts. ")])])]),t("div",{staticClass:"row"},[t("div",{staticClass:"col-xs-12 col-sm-4"},[t("img",{attrs:{width:"100%",src:a(2414),alt:"",srcset:""}})]),t("div",{staticClass:"col-xs-12 col-sm-8"},[t("h4",[e._v(" Exploiting Syntactic Structure for Better Language Modeling: A Syntactic Distance Approach ")]),t("p",{staticClass:"author"},[e._v(" Wenyu Du*, "),t("span",{staticStyle:{"font-weight":"500"}},[e._v("Zhouhan Lin")]),e._v("*, Yikang Shen, Timothy J. O'Donnell, Yoshua Bengio, Yue Zhang# ")]),t("div",{staticClass:"link-list"},[t("span",[e._v(" ACL 2020 ")]),t("span",[e._v(" | ")]),t("a",{attrs:{href:"https://arxiv.org/pdf/2005.05864.pdf"}},[t("span",[e._v("pdf")])]),t("span",[e._v(" | ")]),t("a",{attrs:{href:"t https://github.com/wenyudu/SDLM"}},[t("span",[e._v("codes")])])]),t("article",[e._v(' It is commonly believed that knowledge of syntactic structure should improve language modeling. However, effectively and computationally efficiently incorporating syntactic structure into neural language models has been a challenging topic. In this paper, we make use of a multi-task objective, i.e., the models simultaneously predict words as well as ground truth parse trees in a form called "syntactic distances", where information between these two separate objectives shares the same intermediate representation. Experimental results on the Penn Treebank and Chinese Treebank datasets show that when ground truth parse trees are provided as additional training signals, the model is able to achieve lower perplexity and induce trees with better quality. ')])])]),t("div",{staticClass:"row"},[t("div",{staticClass:"col-xs-12 col-sm-4"},[t("img",{attrs:{width:"100%",src:a(9652),alt:"",srcset:""}})]),t("div",{staticClass:"col-xs-12 col-sm-8"},[t("h4",[e._v(" Straight to the Tree: Constituency Parsing with Neural Syntactic Distance ")]),t("p",{staticClass:"author"},[e._v(" Yikang Shen*, "),t("span",{staticStyle:{"font-weight":"500"}},[e._v("Zhouhan Lin")]),e._v("*, Athul Paul Jacob, Alessandro Sordoni, Aaron Courville, Yoshua Bengio ")]),t("div",{staticClass:"link-list"},[t("span",[e._v("ACL 2018 ")]),t("span",[e._v(" | ")]),t("a",{attrs:{href:"https://arxiv.org/pdf/1806.04168.pdf"}},[t("span",[e._v("pdf")])]),t("span",[e._v(" | ")]),t("a",{attrs:{href:"http://"}},[t("span",[e._v("slides")])]),t("span",[e._v(" | ")]),t("a",{attrs:{href:"https://github.com/hantek/distance-parser"}},[t("span",[e._v("codes")])])]),t("article",[e._v(" We propose a novel constituency parsing scheme. The model predicts a vector of real-valued scalars, named syntactic distances, for each split position in the input sentence. The syntactic distances specify the order in which the split points will be selected, recursively partitioning the input, in a top-down fashion. Compared to traditional shiftreduce parsing schemes, our approach is free from the potential problem of compounding errors, while being faster and easier to parallelize. Our model achieves competitive performance amongst single model, discriminative parsers in the PTB dataset and outperforms previous models in the CTB dataset. ")])])]),t("div",{staticClass:"row"},[t("div",{staticClass:"col-xs-12 col-sm-4"},[t("img",{attrs:{width:"100%",src:a(6358),alt:"",srcset:""}})]),t("div",{staticClass:"col-xs-12 col-sm-8"},[t("h4",[e._v(" Neural Language Modeling by Jointly Learning Syntax and Lexicon ")]),t("p",{staticClass:"author"},[e._v(" Yikang Shen, "),t("span",{staticStyle:{"font-weight":"500"}},[e._v("Zhouhan Lin")]),e._v(", Chin-Wei Huang, Aaron Courville ")]),t("div",{staticClass:"link-list"},[t("span",[e._v("ICLR 2018")]),t("span",[e._v(" | ")]),t("a",{attrs:{href:"https://arxiv.org/pdf/1711.02013.pdf"}},[t("span",[e._v("pdf")])]),t("span",[e._v(" | ")]),t("a",{attrs:{href:"http://https://github.com/yikangshen/PRPN"}},[t("span",[e._v("codes")])])]),t("article",[e._v(" We propose a neural language model capable of unsupervised syntactic structure induction. The model leverages the structure information to form better semantic representations and better language modeling. Standard recurrent neural networks are limited by their structure and fail to efficiently use syntactic information. On the other hand, tree-structured recursive networks usually require additional structural supervision at the cost of human expert annotation. In this paper, We propose a novel neural language model, called the Parsing-Reading-Predict Networks (PRPN), that can simultaneously induce the syntactic structure from unannotated sentences and leverage the inferred structure to learn a better language model. In our model, the gradient can be directly back-propagated from the language model loss into the neural parsing network. Experiments show that the proposed model can discover the underlying syntactic structure and achieve state-of-the-art performance on word/character-level language model tasks. ")])])]),t("div",{staticClass:"row"},[t("div",{staticClass:"col-xs-12 col-sm-4"},[t("img",{attrs:{width:"100%",src:a(5932),alt:"",srcset:""}})]),t("div",{staticClass:"col-xs-12 col-sm-8"},[t("h4",[e._v("A structured self-attentive Sentence Embedding")]),t("p",{staticClass:"author"},[t("span",{staticStyle:{"font-weight":"500"}},[e._v("Zhouhan Lin")]),e._v(", Minwei Feng, Cicero Nogueira dos Santos, Mo Yu, Bing Xiang, Bowen Zhou and Yoshua Bengio ")]),t("div",{staticClass:"link-list"},[t("span",{staticClass:"time"},[e._v("ICLR 2017")]),t("span",[e._v(" | ")]),t("a",{attrs:{href:"https://arxiv.org/pdf/1703.03130.pdf"}},[t("span",[e._v("pdf")])]),t("span",[e._v(" | ")]),t("a",{attrs:{href:"https://github.com/hantek/SelfAttentiveSentEmbed"}},[t("span",[e._v("codes")])])]),t("article",[e._v(" We propose a new model for extracting an interpretable sentence embedding by introducing self-attention. Instead of using a vector, we use a 2-D matrix to represent the embedding, with each row of the matrix attending on a different part of the sentence. We also propose a self-attention mechanism and a special regularization term for the model. As a side effect, the embedding comes with an easy way of visualizing what specific parts of the sentence are encoded into the embedding. We evaluate our model on 3 different tasks: author profiling, sentiment classification, and textual entailment. Results show that our model yields a significant performance gain compared to other sentence embedding methods in all of the 3 tasks. ")])])]),t("div",{staticClass:"row"},[t("div",{staticClass:"col-xs-12 col-sm-4"},[t("img",{attrs:{width:"100%",src:a(8773),alt:"",srcset:""}})]),t("div",{staticClass:"col-xs-12 col-sm-8"},[t("h4",[e._v("Neural networks with few multiplications")]),t("p",{staticClass:"author"},[t("span",{staticStyle:{"font-weight":"500"}},[e._v("Zhouhan Lin")]),e._v(", Matthieu Courbariaux, Roland Memisevic, and Yoshua Bengio ")]),t("div",{staticClass:"link-list"},[t("span",{staticClass:"time"},[e._v("ICLR 2016 (oral)")]),t("span",[e._v(" | ")]),t("a",{attrs:{href:"https://arxiv.org/pdf/1510.03009.pdf"}},[t("span",[e._v("pdf")])]),t("span",[e._v(" | ")]),t("a",{attrs:{href:"https://github.com/hantek/BinaryConnect"}},[t("span",[e._v("codes")])])]),t("article",[e._v(" For most deep learning algorithms training is notoriously time consuming. Since most of the computation in training neural networks is typically spent on floating point multiplications, we investigate an approach to training that eliminates the need for most of these. Our method consists of two parts: First we stochastically binarize weights to convert multiplications involved in computing hidden states to sign changes. Second, while back-propagating error derivatives, in addition to binarizing the weights, we quantize the representations at each layer to convert the remaining multiplications into binary shifts. Experimental results across 3 popular datasets (MNIST, CIFAR10, SVHN) show that this approach not only does not hurt classification performance but can result in even better performance than standard stochastic gradient descent training, paving the way to fast, hardwarefriendly training of neural networks. ")])])]),t("div",{staticClass:"row"},[t("div",{staticClass:"col-xs-12 col-sm-4"},[t("img",{attrs:{width:"100%",src:a(143),alt:"",srcset:""}})]),t("div",{staticClass:"col-xs-12 col-sm-8"},[t("h4",[e._v("Deep learning-based classification of hyperspectral data")]),t("p",{staticClass:"author"},[e._v(" Yushi Chen, "),t("span",{staticStyle:{"font-weight":"500"}},[e._v("Zhouhan Lin")]),e._v(", Xing Zhao, Gang Wang, and Yanfeng Gu ")]),t("div",{staticClass:"link-list"},[t("span",{staticClass:"time"},[e._v("Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 2014")]),t("span",[e._v(" | ")]),t("a",{attrs:{href:"https://ieeexplore.ieee.org/document/6844831/?arnumber=6844831"}},[t("span",[e._v("pdf")])]),t("span",[e._v(" | ")]),t("a",{attrs:{href:"https://github.com/hantek/deeplearn_hsi"}},[t("span",[e._v("codes")])])]),t("article",[e._v(" Classification is one of the most popular topics in hyperspectral remote sensing. In the last two decades, a huge number of methods were proposed to deal with the hyperspectral data classification problem. However, most of them do not hierarchically extract deep features. In this paper, the concept of deep learning is introduced into hyperspectral data classification for the first time. First, we verify the eligibility of stacked autoencoders by following classical spectral information-based classification. Second, a new way of classifying with spatial-dominated information is proposed. We then propose a novel deep learning framework to merge the two features, from which we can get the highest classification accuracy. The framework is a hybrid of principle component analysis (PCA), deep learning architecture, and logistic regression. Specifically, as a deep learning architecture, stacked autoencoders are aimed to get useful high-level features. Experimental results with widely-used hyperspectral data indicate that classifiers built in this deep learning-based framework provide competitive performance. In addition, the proposed joint spectral–spatial deep neural network opens a new window for future research, showcasing the deep learning-based methods’ huge potential for accurate hyperspectral data classification. ")])])])])])])])}];const O={researchList:[{name:"Straight to the Tree: Constituency Parsing with Neural Syntactic Distance",img:"./static/research/distanceparser.png",list:[{name:"ACL 2018"},{name:"pdf",link:"http:"},{name:"slides",link:"http:"},{name:"codes",link:"http:"}],author:"Yikang Shen*, Zhouhan Lin*, Athul Paul Jacob, Alessandro Sordoni, Aaron Courville, Yoshua Bengio",abstract:"We propose a novel constituency parsing scheme. The model predicts a vector of real-valued scalars, named syntactic distances, for each split position in the input sentence. The syntactic distances specify the order in which the split points will be selected, recursively partitioning the input, in a top-down fashion. Compared to traditional shiftreduce parsing schemes, our approach is free from the potential problem of compounding errors, while being faster and easier to parallelize. Our model achieves competitive performance amongst single model, discriminative parsers in the PTB dataset and outperforms previous models in the CTB dataset."},{name:"Straight to the Tree: Constituency Parsing with Neural Syntactic Distance",img:"./static/research/distanceparser.png",list:[{name:"ACL 2018"},{name:"pdf",link:"http:"},{name:"slides",link:"http:"},{name:"codes",link:"http:"}],author:"Yikang Shen*, Zhouhan Lin*, Athul Paul Jacob, Alessandro Sordoni, Aaron Courville, Yoshua Bengio",abstract:"We propose a novel constituency parsing scheme. The model predicts a vector of real-valued scalars, named syntactic distances, for each split position in the input sentence. The syntactic distances specify the order in which the split points will be selected, recursively partitioning the input, in a top-down fashion. Compared to traditional shiftreduce parsing schemes, our approach is free from the potential problem of compounding errors, while being faster and easier to parallelize. Our model achieves competitive performance amongst single model, discriminative parsers in the PTB dataset and outperforms previous models in the CTB dataset."},{name:"Straight to the Tree: Constituency Parsing with Neural Syntactic Distance",img:"./static/research/distanceparser.png",list:[{name:"ACL 2018"},{name:"pdf",link:"http:"},{name:"slides",link:"http:"},{name:"codes",link:"http:"}],author:"Yikang Shen*, Zhouhan Lin*, Athul Paul Jacob, Alessandro Sordoni, Aaron Courville, Yoshua Bengio",abstract:"We propose a novel constituency parsing scheme. The model predicts a vector of real-valued scalars, named syntactic distances, for each split position in the input sentence. The syntactic distances specify the order in which the split points will be selected, recursively partitioning the input, in a top-down fashion. Compared to traditional shiftreduce parsing schemes, our approach is free from the potential problem of compounding errors, while being faster and easier to parallelize. Our model achieves competitive performance amongst single model, discriminative parsers in the PTB dataset and outperforms previous models in the CTB dataset."},{name:"Straight to the Tree: Constituency Parsing with Neural Syntactic Distance",img:"./static/research/distanceparser.png",list:[{name:"ACL 2018"},{name:"pdf",link:"http:"},{name:"slides",link:"http:"},{name:"codes",link:"http:"}],author:"Yikang Shen*, Zhouhan Lin*, Athul Paul Jacob, Alessandro Sordoni, Aaron Courville, Yoshua Bengio",abstract:"We propose a novel constituency parsing scheme. The model predicts a vector of real-valued scalars, named syntactic distances, for each split position in the input sentence. The syntactic distances specify the order in which the split points will be selected, recursively partitioning the input, in a top-down fashion. Compared to traditional shiftreduce parsing schemes, our approach is free from the potential problem of compounding errors, while being faster and easier to parallelize. Our model achieves competitive performance amongst single model, discriminative parsers in the PTB dataset and outperforms previous models in the CTB dataset."},{name:"Straight to the Tree: Constituency Parsing with Neural Syntactic Distance",img:"./static/research/distanceparser.png",list:[{name:"ACL 2018"},{name:"pdf",link:"http:"},{name:"slides",link:"http:"},{name:"codes",link:"http:"}],author:"Yikang Shen*, Zhouhan Lin*, Athul Paul Jacob, Alessandro Sordoni, Aaron Courville, Yoshua Bengio",abstract:"We propose a novel constituency parsing scheme. The model predicts a vector of real-valued scalars, named syntactic distances, for each split position in the input sentence. The syntactic distances specify the order in which the split points will be selected, recursively partitioning the input, in a top-down fashion. Compared to traditional shiftreduce parsing schemes, our approach is free from the potential problem of compounding errors, while being faster and easier to parallelize. Our model achieves competitive performance amongst single model, discriminative parsers in the PTB dataset and outperforms previous models in the CTB dataset."}]};var B={data(){return{researchData:O}}},R=B,W=(0,h.Z)(R,N,D,!1,null,"9b7dbae2",null),Y=W.exports,M=function(){var e=this,t=e._self._c;return t("div",{staticClass:"news-container"},[t("div",{staticClass:"news-content"},[t("ul",e._l(e.newsData.newsList,(function(a,s){return t("li",{key:s},[e._v(" "+e._s(a)+" ")])})),0)])])},H=[];const F={newsList:["2023/01: Two papers are accepted at ICLR 2023.","2023/01: Two papers are accepted at ICLR 2023.","2023/01: Two papers are accepted at ICLR 2023.","2023/01: Two papers are accepted at ICLR 2023."]};var z={data(){return{newsData:F}}},E=z,j=(0,h.Z)(E,M,H,!1,null,"812e5dda",null),G=j.exports,q=function(){var e=this,t=e._self._c;return t("div",{staticClass:"contact-container"},[t("div",{staticClass:"contact-content"},e._l(e.contactData.contactList,(function(a,s){return t("section",{key:s,staticClass:"contact-list"},[t("h2",[e._v(e._s(a.header))]),e._l(a.list,(function(a,s){return t("p",{key:s+"l"},[e._v(e._s(a))])}))],2)})),0)])},J=[];const U={contactList:[{header:"Header 1",list:["This is line 1","This is a line, This is a line,This is a line,This is a line,This is a line,This is a line,This is a line,This is a line,This is a line,This is a line,This is a line,This is a line,This is a line,This is a line,This is a line,This is a line,This is a line,This is a line,This is a line,This is a line,"]},{header:"Header 2",list:["This is line 1"]},{header:"Header 3",list:["This is line 1"]}]};var Q={data(){return{contactData:U}}},V=Q,$=(0,h.Z)(V,q,J,!1,null,"2be34353",null),K=$.exports;s["default"].use(w.ZP);const ee=[{path:"/",name:"home",component:S},{path:"/people",name:"people",component:I},{path:"/research",name:"research",component:Y},{path:"/news",name:"news",component:G},{path:"/contact",name:"contact",component:K}],te=new w.ZP({base:"/",routes:ee});var ae=te,se=a(408);s["default"].use(se.ZP);var ie=new se.ZP.Store({state:{},getters:{},mutations:{},actions:{},modules:{}}),ne=a(5114),re=a.n(ne);s["default"].use(re()),s["default"].config.productionTip=!1,new s["default"]({router:ae,store:ie,render:e=>e(v)}).$mount("#app")},3145:function(e,t,a){e.exports=a.p+"img/avsrpan.33e49bc1.png"},1121:function(e,t,a){e.exports=a.p+"img/blockskim.e76a589c.png"},2414:function(e,t,a){e.exports=a.p+"img/distancelmwenyu.68b90a6e.png"},9652:function(e,t,a){e.exports=a.p+"img/distanceparser.9c498977.png"},63:function(e,t,a){e.exports=a.p+"img/distancetransformer.e7d1d0a2.png"},8773:function(e,t,a){e.exports=a.p+"img/exp_quant.2c72c9a5.png"},9597:function(e,t,a){e.exports=a.p+"img/fouriertransformer.3f1115a7.png"},143:function(e,t,a){e.exports=a.p+"img/hsiclassify.42c617aa.png"},9149:function(e,t,a){e.exports=a.p+"img/lotinsts.c6dd685a.png"},389:function(e,t,a){e.exports=a.p+"img/orderedgnn.2409e1f0.png"},5660:function(e,t,a){e.exports=a.p+"img/rasat.14dd32ad.png"},5932:function(e,t,a){e.exports=a.p+"img/semlp.5b563a83.png"},6358:function(e,t,a){e.exports=a.p+"img/tree.08d4ceca.png"}},t={};function a(s){var i=t[s];if(void 0!==i)return i.exports;var n=t[s]={id:s,loaded:!1,exports:{}};return e[s].call(n.exports,n,n.exports,a),n.loaded=!0,n.exports}a.m=e,function(){a.amdO={}}(),function(){var e=[];a.O=function(t,s,i,n){if(!s){var r=1/0;for(p=0;p<e.length;p++){s=e[p][0],i=e[p][1],n=e[p][2];for(var o=!0,c=0;c<s.length;c++)(!1&n||r>=n)&&Object.keys(a.O).every((function(e){return a.O[e](s[c])}))?s.splice(c--,1):(o=!1,n<r&&(r=n));if(o){e.splice(p--,1);var l=i();void 0!==l&&(t=l)}}return t}n=n||0;for(var p=e.length;p>0&&e[p-1][2]>n;p--)e[p]=e[p-1];e[p]=[s,i,n]}}(),function(){a.n=function(e){var t=e&&e.__esModule?function(){return e["default"]}:function(){return e};return a.d(t,{a:t}),t}}(),function(){a.d=function(e,t){for(var s in t)a.o(t,s)&&!a.o(e,s)&&Object.defineProperty(e,s,{enumerable:!0,get:t[s]})}}(),function(){a.g=function(){if("object"===typeof globalThis)return globalThis;try{return this||new Function("return this")()}catch(e){if("object"===typeof window)return window}}()}(),function(){a.o=function(e,t){return Object.prototype.hasOwnProperty.call(e,t)}}(),function(){a.r=function(e){"undefined"!==typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})}}(),function(){a.nmd=function(e){return e.paths=[],e.children||(e.children=[]),e}}(),function(){a.p="/"}(),function(){var e={143:0};a.O.j=function(t){return 0===e[t]};var t=function(t,s){var i,n,r=s[0],o=s[1],c=s[2],l=0;if(r.some((function(t){return 0!==e[t]}))){for(i in o)a.o(o,i)&&(a.m[i]=o[i]);if(c)var p=c(a)}for(t&&t(s);l<r.length;l++)n=r[l],a.o(e,n)&&e[n]&&e[n][0](),e[n]=0;return a.O(p)},s=self["webpackChunkLUMIA_Group"]=self["webpackChunkLUMIA_Group"]||[];s.forEach(t.bind(null,0)),s.push=t.bind(null,s.push.bind(s))}();var s=a.O(void 0,[998],(function(){return a(7051)}));s=a.O(s)})();
//# sourceMappingURL=app.8b25b006.js.map